{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNjeQb3VnA46DfX5lDIAijb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# ML\n","**Training a Model for Supervised Learning:**\n","1. **Data Preprocessing ** in Data Mining-Data pre-processing increases the quality of the data thus making it fit to be analyzed. It minimizes errors, variations, and duplication, hence enhancing the possibility of getting the right results.\n","*   Data Cleaning\n","*   Data integration\n","*   Data Transformation-normalization, standardization, and discretization\n","*   Data reduction\n","2. **Splitting Data for Machine Learning Models**\n","*   Train-Test Split-70-eighty% for training and 20-30% for checking\n","*   Train-Validation-Test Split-> here validation set is used to tune hyperparameters\n","*   K-fold Cross Validation->k-1 folds are used for training, and 1 fold is used for validation/testing\n","*  Stratified Sampling-solves this problem by maintaining the proportion of different classes (or sub-groups) in both the training and test sets & ensures that both the training and test sets will have the same proportion of each class as the original dataset\n","* Train/Dev/Test sets-> Train, Dev (Development or Validation), and Test sets is crucial for model evaluation\n","3. **Choosing the Model:** Depending on the problem type (e.g., classification or regression), different algorithms are selected\n","4. **Training the Model**: The model is trained by feeding it the input data and output labels\n","5. **Evaluating the Model** - Model evaluation is the process that uses some metrics which help us to analyze the performance of the model.There are many metrics like Accuracy, Precision, Recall, F1 score, Area under Curve, Confusion Matrix, and Mean Square Error. Cross Validation is one technique that is followed during the training phase and it is a model evaluation technique as well.\n","6. **Hyperparameter Tuning **-  its control the learning process itself, rather than being learned from the data and they can have a significant impact on the modelâ€™s accuracy, generalization, and other metrics.\n","    *   Some other examples of model hyperparameters include:\n","        1. The penalty in Logistic Regression Classifier i.e. L1 or L2 regularization\n","        2. Number of Trees and Depth of Trees for Random Forests.\n","        3. The learning rate for training a neural network.\n","        4. Number of Clusters for Clustering Algorithms.\n","        5. The k in k-nearest neighbors.\n","    *  Hyperparameter Tuning techniques:\n","        1. GridSearchCV\n","        2. RandomizedSearchCV\n","        3. Bayesian Optimization\n","7. **Final Model Selection and Testing**: After tuning, the model is retrained on the full dataset (including the validation set if used) using the best hyperparameters. This final model is then tested on the test set to evaluate its performance. This step ensures that the model is ready for deployment, with optimal settings for real-world application, an essential part of training a model for supervised learning.\n","8. **Model Deployment:** Once tested and validated, the model is deployed to make predictions on new, unseen data in production environments. Post-deployment, continuous monitoring is crucial to ensure the model continues to perform well as new data comes in.\n","8. **Iterative Improvement**: Supervised learning models often require refinement. Based on performance feedback, models can be retrained with more data, new features, or different algorithms to improve accuracy. This iterative process is key in ensuring that the model adapts to new patterns in the data.\n","\n","\n"],"metadata":{"id":"vmbYeeCGWyJz"}},{"cell_type":"markdown","source":[],"metadata":{"id":"2oG-hZhZW1f6"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"yskkQOUlWxka"},"outputs":[],"source":[]}]}