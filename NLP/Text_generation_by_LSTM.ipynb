{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "8AqJeSZ1Q5_g",
        "yMMR6zs_SJsF"
      ],
      "mount_file_id": "1woCkc2RwWuL0gvpZjjwMLF4aZtCGxgXU",
      "authorship_tag": "ABX9TyOoA+iZwjSx2AvdQZ6MpYjH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mahemaran/Colab-notebooks/blob/main/Text_generation_by_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Load file and importing**"
      ],
      "metadata": {
        "id": "8AqJeSZ1Q5_g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dybkr8RxNjWI",
        "outputId": "1d8b67fd-f611-44ee-9efe-32402e41ab6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2505\n"
          ]
        }
      ],
      "source": [
        "with open(\"/content/Maran.txt\", \"r\") as book:\n",
        "    content = book.read()\n",
        "print(len(content))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(content[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTUBGFvD09WC",
        "outputId": "ecd768a1-af42-4fed-dc83-d40a32a2780a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maran’s Vision for the Future:\n",
            "Professional Ambition\n",
            "With 3 years of experience in HCL Technologies, Maran is on a mission to accelerate his career in AI. He envisions running a variety of cutting-edge automation and AI projects, driving innovation that pushes the boundaries of what’s possible. His passion for AI spans from machine learning to natural language processing (NLP), and he is constantly seeking opportunities to build intelligent systems that will revolutionize industries.\n",
            "\n",
            "Maran isn’\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "yMTErQm6OwWr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Text preprocessing**"
      ],
      "metadata": {
        "id": "yMMR6zs_SJsF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_split = content.split(\".\")\n",
        "print((text_split))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "negiUgW1Ca_F",
        "outputId": "e5cd9ab6-b1d0-49ee-90c1-5c0655e031a7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Maran’s Vision for the Future:\\nProfessional Ambition\\nWith 3 years of experience in HCL Technologies, Maran is on a mission to accelerate his career in AI', ' He envisions running a variety of cutting-edge automation and AI projects, driving innovation that pushes the boundaries of what’s possible', ' His passion for AI spans from machine learning to natural language processing (NLP), and he is constantly seeking opportunities to build intelligent systems that will revolutionize industries', '\\n\\nMaran isn’t just looking for a job—he wants to make an impact', ' Whether it’s designing smart automation systems, or pioneering AI-driven solutions, he dreams of working on high-impact projects that not only challenge him but also allow him to shape the future of technology', '\\n\\nPersonal Life and Lifestyle\\nMaran envisions a life filled with balance, health, and happiness', ' He dreams of sharing his journey with a fit and healthy lifestyle partner, someone who thrives on being active and leads a wellness-focused lifestyle', ' Together, they would embrace the power of healthy habits, staying active, cooking nutritious meals, and prioritizing mental and physical well-being', \"\\n\\nHome and Living\\nMaran's dream home is a beautiful haven, combining both comfort and functionality\", ' He imagines an expansive living space, where he can design his own gym setup, making it easy to stay committed to his fitness goals', ' With high-end equipment, a spacious layout, and the perfect atmosphere, it would be a place where fitness and strength are nurtured', '\\n\\nThe home would also have a cozy reading nook, a serene space filled with bookshelves lined with novels, self-help books, and more—providing an ideal spot to unwind and fuel both the mind and soul', ' Surrounded by a peaceful atmosphere, this reading space would be where he could immerse himself in learning or dive into new adventures through stories', '\\n\\nAnd, of course, Maran’s home wouldn’t be complete without the warmth and companionship of a cat and dog—two adorable, loyal pets that would make the house feel truly alive', ' Whether it’s cuddling with his furry friends after a long day, or playing with them in the garden, the bond with his pets would add an extra layer of joy and fulfillment to his life', '\\n\\nThis vision highlights the balance between personal ambition and happiness, with a focus on technology, health, and creating the perfect home environment', ' Does this vision resonate with your aspirations? Feel free to let me know if there’s more you want to elaborate on!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_split = [line.strip(\".\") for line in text_split]\n",
        "print(text_split)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DV-QRTOzDTMH",
        "outputId": "aaaeb389-4e34-4ed3-cf86-01cd8e5fd4d8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Maran’s Vision for the Future:\\nProfessional Ambition\\nWith 3 years of experience in HCL Technologies, Maran is on a mission to accelerate his career in AI', ' He envisions running a variety of cutting-edge automation and AI projects, driving innovation that pushes the boundaries of what’s possible', ' His passion for AI spans from machine learning to natural language processing (NLP), and he is constantly seeking opportunities to build intelligent systems that will revolutionize industries', '\\n\\nMaran isn’t just looking for a job—he wants to make an impact', ' Whether it’s designing smart automation systems, or pioneering AI-driven solutions, he dreams of working on high-impact projects that not only challenge him but also allow him to shape the future of technology', '\\n\\nPersonal Life and Lifestyle\\nMaran envisions a life filled with balance, health, and happiness', ' He dreams of sharing his journey with a fit and healthy lifestyle partner, someone who thrives on being active and leads a wellness-focused lifestyle', ' Together, they would embrace the power of healthy habits, staying active, cooking nutritious meals, and prioritizing mental and physical well-being', \"\\n\\nHome and Living\\nMaran's dream home is a beautiful haven, combining both comfort and functionality\", ' He imagines an expansive living space, where he can design his own gym setup, making it easy to stay committed to his fitness goals', ' With high-end equipment, a spacious layout, and the perfect atmosphere, it would be a place where fitness and strength are nurtured', '\\n\\nThe home would also have a cozy reading nook, a serene space filled with bookshelves lined with novels, self-help books, and more—providing an ideal spot to unwind and fuel both the mind and soul', ' Surrounded by a peaceful atmosphere, this reading space would be where he could immerse himself in learning or dive into new adventures through stories', '\\n\\nAnd, of course, Maran’s home wouldn’t be complete without the warmth and companionship of a cat and dog—two adorable, loyal pets that would make the house feel truly alive', ' Whether it’s cuddling with his furry friends after a long day, or playing with them in the garden, the bond with his pets would add an extra layer of joy and fulfillment to his life', '\\n\\nThis vision highlights the balance between personal ambition and happiness, with a focus on technology, health, and creating the perfect home environment', ' Does this vision resonate with your aspirations? Feel free to let me know if there’s more you want to elaborate on!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(text_split)\n",
        "word_index = tokenizer.word_index\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "print(\"The word index:\", word_index)\n",
        "print(\"the total no of words:\", total_words)\n",
        "# Sequence the words\n",
        "# sequences = tokenizer.texts_to_sequences([list(word_index.keys())])\n",
        "sequences = tokenizer.texts_to_sequences(text_split)\n",
        "print((\"-----------------\")*200)\n",
        "print(sequences)\n",
        "print(len(sequences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDRkp04TR98E",
        "outputId": "be0d62ed-353d-469e-ee52-754566df8c40"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The word index: {'and': 1, 'a': 2, 'the': 3, 'with': 4, 'to': 5, 'of': 6, 'his': 7, 'he': 8, 'would': 9, 'on': 10, 'home': 11, 'in': 12, 'ai': 13, 'that': 14, 'an': 15, 'vision': 16, 'for': 17, 'maran': 18, 'is': 19, 'or': 20, 'life': 21, 'lifestyle': 22, 'space': 23, 'where': 24, 'be': 25, 'this': 26, 'maran’s': 27, 'future': 28, 'ambition': 29, 'envisions': 30, 'automation': 31, 'projects': 32, 'learning': 33, 'systems': 34, 'make': 35, 'impact': 36, 'whether': 37, 'it’s': 38, 'dreams': 39, 'high': 40, 'him': 41, 'also': 42, 'technology': 43, 'personal': 44, 'filled': 45, 'balance': 46, 'health': 47, 'happiness': 48, 'healthy': 49, 'being': 50, 'active': 51, 'living': 52, 'both': 53, 'it': 54, 'fitness': 55, 'perfect': 56, 'atmosphere': 57, 'reading': 58, 'pets': 59, 'feel': 60, 'professional': 61, '3': 62, 'years': 63, 'experience': 64, 'hcl': 65, 'technologies': 66, 'mission': 67, 'accelerate': 68, 'career': 69, 'running': 70, 'variety': 71, 'cutting': 72, 'edge': 73, 'driving': 74, 'innovation': 75, 'pushes': 76, 'boundaries': 77, 'what’s': 78, 'possible': 79, 'passion': 80, 'spans': 81, 'from': 82, 'machine': 83, 'natural': 84, 'language': 85, 'processing': 86, 'nlp': 87, 'constantly': 88, 'seeking': 89, 'opportunities': 90, 'build': 91, 'intelligent': 92, 'will': 93, 'revolutionize': 94, 'industries': 95, 'isn’t': 96, 'just': 97, 'looking': 98, 'job—he': 99, 'wants': 100, 'designing': 101, 'smart': 102, 'pioneering': 103, 'driven': 104, 'solutions': 105, 'working': 106, 'not': 107, 'only': 108, 'challenge': 109, 'but': 110, 'allow': 111, 'shape': 112, 'sharing': 113, 'journey': 114, 'fit': 115, 'partner': 116, 'someone': 117, 'who': 118, 'thrives': 119, 'leads': 120, 'wellness': 121, 'focused': 122, 'together': 123, 'they': 124, 'embrace': 125, 'power': 126, 'habits': 127, 'staying': 128, 'cooking': 129, 'nutritious': 130, 'meals': 131, 'prioritizing': 132, 'mental': 133, 'physical': 134, 'well': 135, \"maran's\": 136, 'dream': 137, 'beautiful': 138, 'haven': 139, 'combining': 140, 'comfort': 141, 'functionality': 142, 'imagines': 143, 'expansive': 144, 'can': 145, 'design': 146, 'own': 147, 'gym': 148, 'setup': 149, 'making': 150, 'easy': 151, 'stay': 152, 'committed': 153, 'goals': 154, 'end': 155, 'equipment': 156, 'spacious': 157, 'layout': 158, 'place': 159, 'strength': 160, 'are': 161, 'nurtured': 162, 'have': 163, 'cozy': 164, 'nook': 165, 'serene': 166, 'bookshelves': 167, 'lined': 168, 'novels': 169, 'self': 170, 'help': 171, 'books': 172, 'more—providing': 173, 'ideal': 174, 'spot': 175, 'unwind': 176, 'fuel': 177, 'mind': 178, 'soul': 179, 'surrounded': 180, 'by': 181, 'peaceful': 182, 'could': 183, 'immerse': 184, 'himself': 185, 'dive': 186, 'into': 187, 'new': 188, 'adventures': 189, 'through': 190, 'stories': 191, 'course': 192, 'wouldn’t': 193, 'complete': 194, 'without': 195, 'warmth': 196, 'companionship': 197, 'cat': 198, 'dog—two': 199, 'adorable': 200, 'loyal': 201, 'house': 202, 'truly': 203, 'alive': 204, 'cuddling': 205, 'furry': 206, 'friends': 207, 'after': 208, 'long': 209, 'day': 210, 'playing': 211, 'them': 212, 'garden': 213, 'bond': 214, 'add': 215, 'extra': 216, 'layer': 217, 'joy': 218, 'fulfillment': 219, 'highlights': 220, 'between': 221, 'focus': 222, 'creating': 223, 'environment': 224, 'does': 225, 'resonate': 226, 'your': 227, 'aspirations': 228, 'free': 229, 'let': 230, 'me': 231, 'know': 232, 'if': 233, 'there’s': 234, 'more': 235, 'you': 236, 'want': 237, 'elaborate': 238}\n",
            "the total no of words: 239\n",
            "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "[[27, 16, 17, 3, 28, 61, 29, 4, 62, 63, 6, 64, 12, 65, 66, 18, 19, 10, 2, 67, 5, 68, 7, 69, 12, 13], [8, 30, 70, 2, 71, 6, 72, 73, 31, 1, 13, 32, 74, 75, 14, 76, 3, 77, 6, 78, 79], [7, 80, 17, 13, 81, 82, 83, 33, 5, 84, 85, 86, 87, 1, 8, 19, 88, 89, 90, 5, 91, 92, 34, 14, 93, 94, 95], [18, 96, 97, 98, 17, 2, 99, 100, 5, 35, 15, 36], [37, 38, 101, 102, 31, 34, 20, 103, 13, 104, 105, 8, 39, 6, 106, 10, 40, 36, 32, 14, 107, 108, 109, 41, 110, 42, 111, 41, 5, 112, 3, 28, 6, 43], [44, 21, 1, 22, 18, 30, 2, 21, 45, 4, 46, 47, 1, 48], [8, 39, 6, 113, 7, 114, 4, 2, 115, 1, 49, 22, 116, 117, 118, 119, 10, 50, 51, 1, 120, 2, 121, 122, 22], [123, 124, 9, 125, 3, 126, 6, 49, 127, 128, 51, 129, 130, 131, 1, 132, 133, 1, 134, 135, 50], [11, 1, 52, 136, 137, 11, 19, 2, 138, 139, 140, 53, 141, 1, 142], [8, 143, 15, 144, 52, 23, 24, 8, 145, 146, 7, 147, 148, 149, 150, 54, 151, 5, 152, 153, 5, 7, 55, 154], [4, 40, 155, 156, 2, 157, 158, 1, 3, 56, 57, 54, 9, 25, 2, 159, 24, 55, 1, 160, 161, 162], [3, 11, 9, 42, 163, 2, 164, 58, 165, 2, 166, 23, 45, 4, 167, 168, 4, 169, 170, 171, 172, 1, 173, 15, 174, 175, 5, 176, 1, 177, 53, 3, 178, 1, 179], [180, 181, 2, 182, 57, 26, 58, 23, 9, 25, 24, 8, 183, 184, 185, 12, 33, 20, 186, 187, 188, 189, 190, 191], [1, 6, 192, 27, 11, 193, 25, 194, 195, 3, 196, 1, 197, 6, 2, 198, 1, 199, 200, 201, 59, 14, 9, 35, 3, 202, 60, 203, 204], [37, 38, 205, 4, 7, 206, 207, 208, 2, 209, 210, 20, 211, 4, 212, 12, 3, 213, 3, 214, 4, 7, 59, 9, 215, 15, 216, 217, 6, 218, 1, 219, 5, 7, 21], [26, 16, 220, 3, 46, 221, 44, 29, 1, 48, 4, 2, 222, 10, 43, 47, 1, 223, 3, 56, 11, 224], [225, 26, 16, 226, 4, 227, 228, 60, 229, 5, 230, 231, 232, 233, 234, 235, 236, 237, 5, 238, 10]]\n",
            "17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Padding\n",
        "pad_seq = pad_sequences(sequences)\n",
        "# print(pad_seq)\n",
        "print(len(pad_seq))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evcmaTunGx-e",
        "outputId": "8a2b2035-18e0-4c60-8879-b7b2cd376819"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(pad_seq[1]))\n",
        "print(pad_seq.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H015qLLTIwkG",
        "outputId": "42dda2ca-42f2-4a02-e3f6-b9410a1c0a24"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35\n",
            "(17, 35)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model Building**"
      ],
      "metadata": {
        "id": "QgY-ePYCRfQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "input_shape = pad_seq.shape[1]\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 256, input_length=input_shape))\n",
        "model.add(LSTM(256,dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "model.build(input_shape=(None, input_shape))"
      ],
      "metadata": {
        "id": "6jY7HIXEReJ4"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "afIb_d7fR8Ds",
        "outputId": "59b79edf-cf9b-402d-d7f8-67a78247daa5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │          \u001b[38;5;34m61,184\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m525,312\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m239\u001b[0m)                 │          \u001b[38;5;34m61,423\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">61,184</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">239</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">61,423</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m647,919\u001b[0m (2.47 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">647,919</span> (2.47 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m647,919\u001b[0m (2.47 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">647,919</span> (2.47 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Function to add randomness to predictions\n",
        "def temperature_sampling(predictions, temperature=1.0):\n",
        "    predictions = np.asarray(predictions).astype(\"float64\")\n",
        "    predictions = np.log(predictions + 1e-9) / temperature\n",
        "    exp_preds = np.exp(predictions)\n",
        "    probabilities = exp_preds / np.sum(exp_preds)\n",
        "    return np.random.choice(len(probabilities), p=probabilities)\n",
        "\n",
        "# Function to generate text with n-gram filtering\n",
        "def generate_text(model, tokenizer, seed_text, max_sequence_length, num_words_to_generate, temperature=1.0, n_gram_filter=3):\n",
        "    generated_words = seed_text.split()\n",
        "\n",
        "    for _ in range(num_words_to_generate):\n",
        "        token_list = tokenizer.texts_to_sequences([' '.join(generated_words)])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_length - 1, padding='pre')\n",
        "\n",
        "        # Predict next word probabilities\n",
        "        predicted_probs = model.predict(token_list, verbose=0)[0]\n",
        "        predicted_index = temperature_sampling(predicted_probs, temperature)\n",
        "\n",
        "        # Convert index to word\n",
        "        output_word = ''\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted_index:\n",
        "                output_word = word\n",
        "                break\n",
        "\n",
        "        # Avoid n-gram repetition\n",
        "        if len(generated_words) >= n_gram_filter:\n",
        "            last_n_gram = ' '.join(generated_words[-n_gram_filter:])\n",
        "            if output_word in last_n_gram:\n",
        "                continue  # Skip if repetition occurs\n",
        "\n",
        "        generated_words.append(output_word)\n",
        "\n",
        "    return ' '.join(generated_words)\n",
        "\n",
        "# Example usage\n",
        "seed_text = \"Maran envisions a life filled with\"\n",
        "num_words_to_generate = 50\n",
        "generated_text = generate_text(model, tokenizer, seed_text, input_shape, num_words_to_generate, temperature=0.7)\n",
        "\n",
        "print(\"Generated Text:\")\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ELhcGUf5T9v",
        "outputId": "c9e0573d-290e-4470-ec69-dd986aa43bf9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text:\n",
            "Maran envisions a life filled with habits peaceful novels it’s day possible bookshelves that in pioneering have him home technology beautiful cutting elaborate maran’s garden does add perfect or unwind have driven layout books home machine being fulfillment wellness revolutionize the cozy systems if have fulfillment comfort vision processing focused extra through systems\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Text preprocessing  by Tranformers**"
      ],
      "metadata": {
        "id": "3Im7t8gGG-xL"
      }
    },
    {
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# Load the GPT-2 tokenizer and model\n",
        "model_name = \"gpt2\"  # You can use other models like \"EleutherAI/gpt-neo-125M\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "# Set the padding token to the EOS token (for compatibility)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Open and read the content of the text file\n",
        "with open(\"/content/Maran.txt\", \"r\") as book:\n",
        "    content = book.read()\n",
        "\n",
        "# Print length of the content\n",
        "print(\"Length of the content:\", len(content))\n",
        "\n",
        "# Split the content into sentences (based on full stops)\n",
        "text_split = content.split(\".\")\n",
        "print(f\"Text split into {len(text_split)} sentences\")\n",
        "\n",
        "# Clean up the text by stripping extra spaces from each sentence\n",
        "text_split = [line.strip() for line in text_split if line.strip()]\n",
        "print(text_split[:5])  # Print the first 5 cleaned sentences to verify\n",
        "\n",
        "# Tokenize the text and pad dynamically\n",
        "inputs = tokenizer(text_split, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "# Create the attention mask (automatically created by tokenizer)\n",
        "attention_mask = inputs['attention_mask']\n",
        "print(f\"Input shape: {inputs['input_ids'].shape}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xsaGWrlHihj",
        "outputId": "aaeaf10a-87e3-4fd6-8d88-a1fc589470f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of the content: 2505\n",
            "Text split into 17 sentences\n",
            "['Maran’s Vision for the Future:\\nProfessional Ambition\\nWith 3 years of experience in HCL Technologies, Maran is on a mission to accelerate his career in AI', 'He envisions running a variety of cutting-edge automation and AI projects, driving innovation that pushes the boundaries of what’s possible', 'His passion for AI spans from machine learning to natural language processing (NLP), and he is constantly seeking opportunities to build intelligent systems that will revolutionize industries', 'Maran isn’t just looking for a job—he wants to make an impact', 'Whether it’s designing smart automation systems, or pioneering AI-driven solutions, he dreams of working on high-impact projects that not only challenge him but also allow him to shape the future of technology']\n",
            "Input shape: torch.Size([17, 47])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text_transformer(seed_text, num_words_to_generate, model, tokenizer):\n",
        "    # Tokenize the input seed text and convert it to tensor\n",
        "    input_ids = tokenizer.encode(seed_text, return_tensors=\"pt\")\n",
        "\n",
        "    # Create attention mask (all tokens are attended to)\n",
        "    attention_mask = torch.ones_like(input_ids)\n",
        "\n",
        "    # Generate text using the model\n",
        "    output = model.generate(\n",
        "        input_ids=input_ids,  # Input seed tokens\n",
        "        max_length=len(input_ids[0]) + num_words_to_generate,  # Control text length\n",
        "        num_return_sequences=1,  # Generate one sequence\n",
        "        temperature=0.7,  # Controls randomness\n",
        "        top_p=0.9,  # Nucleus sampling (focus on top probabilities)\n",
        "        do_sample=True,  # Sampling mode (not greedy decoding)\n",
        "        pad_token_id=tokenizer.eos_token_id,  # Ensure stopping at EOS token\n",
        "        attention_mask=attention_mask  # Use attention mask for the seed text\n",
        "    )\n",
        "\n",
        "    # Decode the generated token IDs back to text\n",
        "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    return generated_text\n",
        "\n",
        "# Input seed text for generation\n",
        "seed_text = \"Maran’s Professional Ambition\"\n",
        "# seed_text = content[:1000]\n",
        "num_words_to_generate = 50\n",
        "# num_words_to_generate = 25  # Number of words to generate\n",
        "\n",
        "# Generate text based on the seed text\n",
        "generated_text = generate_text_transformer(seed_text, num_words_to_generate, model, tokenizer)\n",
        "\n",
        "# Display generated text\n",
        "print(\"\\nGenerated Text:\")\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "dID3lctHHoyh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}